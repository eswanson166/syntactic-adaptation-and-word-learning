---
title: "Experiment 1 data visualization"
output: word_document
---

## Load packages

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
source("helpers.R")
library(dplyr)
library(tidyverse)
library(ggplot2)
library(lme4)
library(wesanderson)

theme_set(theme_bw())
```

## Load the data

Note: if you have not run the data cleaning code, then the .zip file with clean data must be unzipped before running this code.
```{r}
et_data <- read.csv("../data/clean_data.csv", stringsAsFactors = TRUE)
```

Check how much data we retain when we only count looks to the action video or the object video.
```{r}
length(et_data$x[et_data$look_left_video == TRUE | 
                   et_data$look_right_video == TRUE]) / length(et_data$x)
```

We retain about 45% of the data. The high rate of track loss is not surprising given how noisy online eye-tracking is.

## Test trials analysis

We want to examine the test trials, specifically during the event stage when participants hear the ambiguous word and see both videos. We exclude looks that aren't to one of the two videos.
```{r}
test_data <- et_data %>% filter(descriptor_condition == "test",
                                video_stage == "event",
                                look_left_video == TRUE | 
                                  look_right_video == TRUE)
```

Add a column for proportion of looks to the action video on each test trial. We will only examine proportion of looks to the action video, since the proportion of looks to the object video is simply 1 - (proportion of looks to the action video).
```{r}
test_data <- test_data %>% group_by(participant_id, trial_no) %>% mutate(trial_prop_action = mean(look_action_video))
```

We also do this for the left and right videos (which we will use for sanity checks).
```{r}
test_data <- test_data %>% group_by(participant_id, trial_no) %>%
  mutate(trial_prop_left = mean(look_left_video),
         trial_prop_right = mean(look_right_video))
```

Make a data frame with only one row per participant trial:
```{r}
test_data_uniq <- test_data %>% group_by(participant_id, trial_no) %>%
  filter(row_number() == 1) %>% group_by(participant_id) %>%
  mutate(subj_prop_action = mean(trial_prop_action))
```

### Proportion of looks to the left and right videos

Before we go on to the main analysis, we want to verify that there is not a bias toward looking to the left or right videos.

Calculate confidence intervals for the mean proportion of looks to the left and right videos.
```{r}
test_left_right <- test_data %>% group_by(participant_id) %>%
  summarise(left = mean(trial_prop_left),
            right = mean(trial_prop_right)) %>%
  gather(screen_side, mean_prop_looks, left:right, 
         factor_key = TRUE) %>%
  group_by(screen_side) %>% 
  summarise(side_prop_looks = mean(mean_prop_looks),
            CI.low = ci.low(mean_prop_looks),
            CI.high = ci.high(mean_prop_looks)) %>%
  mutate(YMin = side_prop_looks - CI.low, 
         YMax = side_prop_looks + CI.high)
```

Graph the mean proportion of looks to the left and right videos.
```{r}
ggplot(test_left_right) +
  aes(x = screen_side, y = side_prop_looks, fill = screen_side) +
  geom_bar(stat = "identity") +
  ggtitle("Test trials: Mean proportion of looks to left and right videos") +
  xlab("Screen side") +
  ylab("Proportion of looks") +
  geom_errorbar(aes(ymin = YMin, ymax = YMax), width = .25) +
  scale_fill_manual(name="Screen side",
                    values=wes_palette("Royal1")[1:2])
ggsave(file="../graphs/prop_looks_left_right.pdf",width=5.5,height=4)
```

The confidence intervals for proportion of looks to the left and right videos overlap. This is what we would expect.

### Proportion of looks based on order

We had two possible orders that determined whether participants saw the action video or the object video first on each trial. Note that each order was counterbalanced for which video appeared first and which side of the screen it appeared on, so we do not expect this to affect the proportion of looks.

Calculate confidence intervals for the mean proportion of looks to the action video based on participant order.
```{r}
order_sum <- test_data_uniq %>% group_by(order) %>% 
summarise(order_prop_action = mean(subj_prop_action),
          CI.Low = ci.low(subj_prop_action),
          CI.High = ci.high(subj_prop_action)) %>%
  mutate(YMin = order_prop_action - CI.Low, 
         YMax = order_prop_action + CI.High)
```

Graph these confidence intervals.
```{r}
ggplot(order_sum) +
  aes(x = order, y = order_prop_action, fill = order) +
  geom_bar(stat = "identity") +
  scale_fill_manual(name = "Order",values = wes_palette("Royal1")[1:2],
                    labels = c("order 1", "order 2")) +
  ggtitle("Test trials: Mean proportion of looks to action video based on order") +
  xlab("Order") +
  ylab("Mean proportion of looks") +
  geom_point(data = test_data_uniq, aes(x = order, y = subj_prop_action),
             shape = 21, size = .3) +
  geom_errorbar(data = order_sum, 
                aes(ymin = YMin, ymax = YMax), width = .25)
ggsave(file="../graphs/prop_looks_order.pdf",width=6,height=4)
```

### Proportion of looks to the action video: Test trials

This is our main measure of interest: the proportion of looks to the action video on test trials. We expect participants in the verb condition to have a higher proportion of looks to the action video.

Calculate confidence intervals for the mean proportion of looks to the action video by condition.
```{r}
test_action_sum <- test_data_uniq %>% group_by(participant_id) %>%
  filter(row_number() == 1) %>% group_by(condition) %>% 
  # note: we pull out only the first row because each subject only has ONE mean calculated across all three test trials and we don't want to triple-count each data point
summarise(cond_prop_action = mean(subj_prop_action),
          sd = sd(subj_prop_action),
          CI.Low = ci.low(subj_prop_action),
          CI.High = ci.high(subj_prop_action),
          n = n()) %>%
  mutate(YMin = cond_prop_action - CI.Low, 
         YMax = cond_prop_action + CI.High)
```

Then, we can make a plot with the confidence intervals as well as individual dots to represent each participant's mean proportion of looks to the action video.
```{r}
ggplot(test_action_sum) +
  aes(x = condition, y = cond_prop_action, fill = condition) +
  geom_bar(stat = "identity") +
  scale_fill_manual(name = "Condition",values = c(wes_palette("Royal1")[2], "dodgerblue3")) +
  ggtitle("Exp. 1 test trials: Participants' mean proportion of looks to action video") +
  xlab("Condition") +
  ylab("Mean proportion of looks") +
  geom_point(data = test_data_uniq, aes(x = condition, y = subj_prop_action),
             shape = 21, size = .3) +
  geom_errorbar(data = test_action_sum, 
                aes(ymin = YMin, ymax = YMax), width = .25)
ggsave(file="../graphs/prop_looks_test.pdf",width=6,height=4)
```

Participants in the verb condition are looking significantly more at the action video.

### Time course

Plot a single participant's time course data:
```{r}
test_data$trial_name <- ifelse(test_data$trial_no == 7, "Trial 7",
                               ifelse(test_data$trial_no == 8, "Trial 8",
                                      ifelse(test_data$trial_no == 9, "Trial 9", NA)))
p1 <- test_data %>% filter(participant_id == 143238)
unique(p1$condition) # they are in the verb condition

# get the proportion of looks on each test trial
unique(p1$trial_prop_action)

ggplot(p1) +
  aes(x = time_since_trial_start, y = look_action_video, color = look_action_video) +
  geom_point() +
  facet_grid(trial_name ~ .) +
  ggtitle("One participant's looks to action video on test trials") +
  xlab("Time since trial start (ms) during event phase") +
  ylab("Looking to action video") +
  scale_color_manual(name="Looking to action video", 
                     values = wes_palette("Royal1")[1:2])
ggsave(file="../graphs/single_timecourse.pdf",width=7,height=3.5)
```

This participant has a high proportion of looks to the action video on trials 7 and 9, and a low proportion of looks on trial 8.


Separate the data into timebins.
```{r}
test_data_timecourse <- test_data %>% 
  mutate(timebin = plyr::round_any(time_since_trial_start, 500)) %>%
  mutate(timebin_ms = timebin/10) %>%
  filter(timebin_ms <= 10000) %>%
  mutate(timebin_ms_from_start = timebin_ms - 2900)
```

Plot the time course collapsing by trial number.
```{r}
prop_action_timecourse_sum <- test_data_timecourse %>% 
  group_by(timebin_ms_from_start, condition) %>% 
  summarise(timebin_prop_action = mean(look_action_video))
```

Make the plot.
```{r}
ggplot(prop_action_timecourse_sum) +
  aes(x = timebin_ms_from_start, y = timebin_prop_action, color = condition) +
  geom_point(size = .3) +
  geom_smooth() +
  ggtitle("Exp 1: Proportion of looks to action video on test trials") +
  xlab("Time since images appeared on-screen (ms)") +
  ylab("") +
  ylim(c(0, 1)) +
  scale_color_manual(name="Condition", limits = c("baseline", "noun", "verb"), values = c(wes_palette("Royal1")[1], wes_palette("Royal1")[2], "dodgerblue3")) +
  geom_hline(yintercept = .5, linetype = "dashed") +
  scale_x_continuous(breaks = seq(min(prop_action_timecourse_sum$timebin_ms_from_start), max(prop_action_timecourse_sum$timebin_ms_from_start), by = 1000))
ggsave(file="../graphs/timecourse_smooth.pdf",width=8,height=5)
```

## Training trials analysis

We can analyze the training trial data to confirm that participants are looking at the video that is described.

Select the training trials only (not including the filler trials).
```{r}
train_data <- et_data %>% filter(descriptor_condition == "noun" |
                                   descriptor_condition == "verb",
                                  look_left_video == TRUE |
                                    look_right_video == TRUE)
```

### Looks to action video during event stage

First, we examine the event stage, which is when participants hear the descriptor. Participants in the verb condition hear a phrase with a verb, while participants in the noun condition hear a phrase with a noun.
```{r}
train_event <- train_data %>% filter(video_stage == "event")
```

Add a column for proportion of looks on each training trial.
```{r}
train_event <- train_event %>% group_by(participant_id, trial_no) %>% mutate(trial_prop_action = mean(look_action_video),
         trial_prop_object = mean(look_object_video))
```

Make a data frame with just one row per participant per trial, and add a column for each participant's mean proportion of looks across the four training trials..
```{r}
train_event_uniq <- train_event %>% group_by(participant_id, trial_no) %>%
  filter(row_number() == 1) %>% group_by(participant_id) %>%
  mutate(subj_prop_action = mean(trial_prop_action),
         subj_prop_object = mean(trial_prop_object))
```

Calculate confidence intervals for the mean proportion of looks to the action video by condition.
```{r}
train_ev_action_sum <- train_event_uniq %>% group_by(participant_id) %>%
  filter(row_number() == 1) %>% group_by(condition) %>% 
summarise(cond_prop_action = mean(subj_prop_action),
          sd = sd(subj_prop_action),
          CI.Low = ci.low(subj_prop_action),
          CI.High = ci.high(subj_prop_action),
          n = n()) %>%
  mutate(YMin = cond_prop_action - CI.Low, 
         YMax = cond_prop_action + CI.High)
```

Graph these confidence intervals, along with dots representing individual participants.
```{r}
ggplot(train_ev_action_sum) +
  aes(x = condition, y = cond_prop_action, fill = condition) +
  geom_bar(stat = "identity") +
  scale_fill_manual(name = "Condition",values = wes_palette("Royal1")[1:2]) +
  ggtitle("Training trials: Mean proportion of looks to action video on event phase") +
  xlab("Condition") +
  ylab("Mean proportion of looks") +
  geom_point(data = train_event_uniq, aes(x = condition, y = subj_prop_action),
             shape = 21, size = .3) +
  geom_errorbar(data = train_ev_action_sum, 
                aes(ymin = YMin, ymax = YMax), width = .25)
ggsave(file="../graphs/prop_looks_train_event.pdf",width=6.5,height=4)
```

Participants in the verb condition are looking much more at the action video when they hear the descriptor, which is what we would expect since they hear phrases with verbs in them. Participants in the noun condition are looking much more at the object video, since they hear phrases with nouns in them.

### Looks to action video during video previews

First, select the time periods when the video previews are playing. During the previews, only one video is playing, so we expect participants to look at the video that plays no matter what their condition is.
```{r}
preview_data <- train_data %>% filter(video_stage == "left_preview" |
                                       video_stage == "right_preview")
```

Add a column saying whether it is the action video preview.
```{r}
preview_data <- preview_data %>% 
  mutate(action_preview = (video_stage == "left_preview" & 
                             action_video == "left") |
           (video_stage == "right_preview" &
              action_video == "right"))
```

Add a column for proportion of looks on each training trial.
```{r}
preview_data <- preview_data %>% 
  group_by(participant_id, trial_no, action_preview) %>%
  mutate(trial_prop_action = mean(look_action_video),
         trial_prop_object = mean(look_object_video))
```

Add a column for each participant's proportion of looks across the four training trials.
```{r}
preview_data_uniq <- preview_data %>% 
  group_by(participant_id, action_preview) %>%
  filter(row_number() == 1) %>%
  mutate(subj_prop_action = mean(trial_prop_action),
         subj_prop_object = mean(trial_prop_object))
```

Calculate confidence intervals for the mean proportion of looks to the action and object videos by condition.
```{r}
preview_sum <- preview_data_uniq %>% 
  group_by(condition, action_preview) %>% 
  summarise(cond_prop_action = mean(subj_prop_action),
            CI.Low = ci.low(subj_prop_action),
            CI.High = ci.high(subj_prop_action),
            n = n()) %>%
  mutate(YMin = cond_prop_action - CI.Low, 
         YMax = cond_prop_action + CI.High)
```

Graph the proportion of looks toward the action video when it is the only video playing.
```{r}
ggplot(preview_sum) +
  aes(x = action_preview, y = cond_prop_action, fill = condition) +
  geom_bar(stat = "identity", position = "dodge") +
  ggtitle("Training trials: Mean proportion of looks during video previews") +
  xlab("Type of video preview") +
  ylab("Mean proportion of looks") +
  scale_fill_manual(name="Condition",values=wes_palette("Royal1")[1:2]) +
  scale_x_discrete(labels = c("Object video", "Action video")) +
  geom_errorbar(aes(ymin = YMin, ymax = YMax), width = .25, 
                position = position_dodge(width = .9))
ggsave(file="../graphs/prop_looks_train_preview_bar.pdf",width=6,height=4)
```

We see no difference in looking patterns by condition, which reassures us that the eye-tracker is in fact measuring which video participants are looking at.

## Filler trials analysis

On filler trials, we expect the pattern to be reversed: Participants in the noun condition should look more at the action video, and participants in the verb condition should look more at the object video.

Get data for filler trials specifically.
```{r}
filler_data <- et_data %>% filter(descriptor_condition == "noun_filler" |
                                    descriptor_condition == "verb_filler",
                                  video_stage == "event",
                                  look_left_video == TRUE | 
                                  look_right_video == TRUE)
```

Add a column for proportion of looks on each training trial.
```{r}
filler_data <- filler_data %>% group_by(participant_id, trial_no) %>% mutate(trial_prop_action = mean(look_action_video))
```

Add a column for each participant's mean proportion of looks across the four training trials.
```{r}
filler_data_uniq <- filler_data %>% group_by(participant_id) %>%
  filter(row_number() == 1) %>%
  mutate(subj_prop_action = mean(trial_prop_action))
```

Calculate confidence intervals for the mean proportion of looks to the action video by condition.
```{r}
filler_sum <- filler_data_uniq %>% group_by(condition) %>% 
summarise(cond_prop_action = mean(subj_prop_action),
          sd = sd(subj_prop_action),
          CI.Low = ci.low(subj_prop_action),
          CI.High = ci.high(subj_prop_action),
          n = n()) %>%
  mutate(YMin = cond_prop_action - CI.Low, 
         YMax = cond_prop_action + CI.High)
```

Graph these confidence intervals, and add individual dots to represent each participant's mean proportion of looks to the action video.
```{r}
ggplot(filler_sum) +
  aes(x = condition, y = cond_prop_action, fill = condition) +
  geom_bar(stat = "identity") +
  scale_fill_manual(name = "Condition",values = wes_palette("Royal1")[1:2]) +
  ggtitle("Filler trials: Mean proportion of looks to action video") +
  xlab("Condition") +
  ylab("Mean proportion of looks") +
  geom_point(data = filler_data_uniq, aes(x = condition, y = subj_prop_action),
             shape = 21, size = .3) +
  geom_errorbar(data = filler_sum, 
                aes(ymin = YMin, ymax = YMax), width = .25)
ggsave(file="../graphs/prop_looks_filler.pdf",width=6,height=4)
```

As expected, participants in the noun condition are looking more at the action video and participants in the verb condition are looking more at the object video.

## Generalization trial

We are curious about whether participants will generalize their expectations about the unfamiliar words to a slightly different structure: Le petit... (noun/verb). This is a purely exploratory analysis.

```{r}
gen_data <- et_data %>% filter(descriptor_condition == "gen",
                                  video_stage == "event",
                                  look_left_video == TRUE | 
                                  look_right_video == TRUE)
```

Add a column for proportion of looks on the trial.
```{r}
gen_data_uniq <- gen_data %>% group_by(participant_id, trial_no) %>%
  mutate(trial_prop_action = mean(look_action_video)) %>%
  filter(row_number() == 1)
```

Calculate confidence intervals for the mean proportion of looks to the action video by condition.
```{r}
gen_sum <- gen_data_uniq %>% group_by(condition) %>% 
summarise(cond_prop_action = mean(trial_prop_action),
          sd = sd(trial_prop_action),
          CI.Low = ci.low(trial_prop_action),
          CI.High = ci.high(trial_prop_action)) %>%
  mutate(YMin = cond_prop_action - CI.Low, 
         YMax = cond_prop_action + CI.High)
```

Graph these confidence intervals, and add individual dots to represent each participant's mean proportion of looks to the action video.
```{r}
ggplot(gen_sum) +
  aes(x = condition, y = cond_prop_action, fill = condition) +
  geom_bar(stat = "identity") +
  scale_fill_manual(name = "Condition",values = wes_palette("Royal1")[1:2]) +
  ggtitle("Generalization trial: Mean proportion of looks to action video") +
  xlab("Condition") +
  ylab("Mean proportion of looks") +
  geom_point(data = gen_data_uniq, aes(x = condition, y = trial_prop_action),
             shape = 21, size = .3) +
  geom_errorbar(data = gen_sum, 
                aes(ymin = YMin, ymax = YMax), width = .25)
ggsave(file="../graphs/prop_looks_gen.pdf",width=6,height=4)
```

Participants in the verb condition seem to be looking more at the action video than participants in the noun condition, but we are not certain whether this difference is significant.



